#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass elsarticle
\begin_preamble
\tnotetext[t1]{This document is a collaborative effort.}
%\tnotetext[t2]{The second title footnote which is a longer
%longer than the first one and with an intention to fill
%in up more than one line while formatting.}
%\author[rvt]{E.F.~Luque\corref{cor1}\fnref{fn1}}
%\ead{edluquem@usp.br.com}
\author[rvt]{E.F.~Luque\corref{cor1}}
\ead{edluquem@usp.br.com}
\author[rvt]{D.~Moreira\corref{cor1}}
\ead{edluquem@usp.br.com}
\author[focal]{D.~Rubin\fnref{fn2}}
\ead{.....com}


%\ead[url]{http://www.elsevier.com}
%\cortext[cor1]{Corresponding author}
%\cortext[cor2]{Principal corresponding author}
%\fntext[fn1]{This is the specimen author footnote.}
%\fntext[fn2]{Another author footnote, but a little more
%longer.}
%\fntext[fn3]{Yet another author footnote. Indeed, you can have
%any number of author footnotes.}

\address[rvt]{Department of Computer Science\\ University of São Paulo\\ São Carlos, Brazil}
\address[focal]{Department of Radiology\\ Stanford University\\ Stanford, USA\\}
%\address[els]{Department of Computer Science\\ University of São Paulo\\ São Carlos, Brazil}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{frontmatter}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
title{Automatic Classification of Cancer Tumors using Image Annotations
 and Ontologies}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{abstract}
\end_layout

\begin_layout Plain Layout

Information about cancer stage in a patient is crucial when clinicians assess
 treatment progress.
 Determining cancer stage is a process that takes into account the description,
 location, characteristics and possible metastasis of cancerous tumors in
 a patient.
 It should follow classification standards, such as TNM Classification of
 Malignant Tumors.
 However, in clinical practice, the implementation of this process can be
 tedious and error-prone and create uncertainty.
 In order to alleviate these problems, we intend to assist radiologists
 by providing a second opinion in the evaluation of cancer stage in patients
 a TNM classifier.
 For doing this, Semantic Web technologies, such as ontologies and reasoning,
 were used to automatically classify cancer stages.
 This classification used semantic annotations, made by radiologists using
 the ePAD tool and stored it in the AIM format, and rules of an ontology
 representing the TNM standard.
 The whole process was validated with users from the Radiology Dept.
 of the Stanford University.
\end_layout

\begin_layout Plain Layout


\backslash
end{abstract}
\end_layout

\begin_layout Plain Layout


\backslash
begin{keyword}
\end_layout

\begin_layout Plain Layout

Reasoning,
\end_layout

\begin_layout Plain Layout

Image Annotations, Cancer Staging, ePAD, OWl
\end_layout

\begin_layout Plain Layout


\backslash
end{keyword}
\end_layout

\begin_layout Plain Layout


\backslash
end{frontmatter}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
In radiology and oncology, evaluating the response to cancer treatments
 depends critically on the results of image analysis by experts.
 However, the information obtained from this analysis is not easily interpreted
 by machines.
 Medical images in clinical tasks are important as they allow specialists
 to diagnose, plan and track patients 
\begin_inset CommandInset citation
LatexCommand citep
key "Levy2009"

\end_inset

.
 Thus, a considerable number of computer applications, have been developed.
 Most of them are focused on extracting visual features with the help of
 image processing algorithms.
 
\end_layout

\begin_layout Standard
Although these algorithms can help physicians to process image contents
 for cancer treatment, they have problems when an abstract query is made
 in the context of cancer patient classification.
 For example, when an oncologist wants to know if a tumor is at an advanced
 stage and it expanded to some region near the origin of cancer but not
 for other parts of the body
\begin_inset CommandInset citation
LatexCommand cite
key "Wennerberg2011155"

\end_inset

.
 There are difficulties during image interpretation, because the semantic
 information implicit in the image reports, is not accessible to these algorithm
s.
 
\end_layout

\begin_layout Standard
Although medical images and reports provide a significant amount of information
 to physicians, this information can not be easily integrated into advanced
 medical applications such as clinical decision support systems to treat
 patients with cancer.
 Specifically, when physicians will assess individual progress of a cancer
 patient to decide new treatment measures 
\begin_inset CommandInset citation
LatexCommand cite
key "Zillner2013"

\end_inset

.
 An appropriate treatment options is supported by the information about
 cancer staging.
 The cancer staging is a classification process based on characteristics
 such as size and location of tumor on the body.
 This classification process can be automated in order to optimize the work
 of the physicians, that may become cumbersome and error prone as the number
 of patients is considerably large
\begin_inset CommandInset citation
LatexCommand cite
key "Zillner2010"

\end_inset

.
\end_layout

\begin_layout Standard
Otherwise, there are few tools that allow radiologists to easily capture
 semantic structured information as part of their routine research workflow
 
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2014"

\end_inset

.
 The project Annotation and Image Markup (AIM) developed by the cancer Biomedica
l Informatics Grid (caBIG) 
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2008"

\end_inset

, provides an XML schema to describe the anatomical structure and visual
 observations images using the RadLex ontology 
\begin_inset CommandInset citation
LatexCommand cite
key "Kundu2009"

\end_inset

.
 It allows a representation, storage, and consistent transfer of semantic
 meanings of images.
 Tools such as the ePAD 
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2014"

\end_inset

, using AIM format can help to reduce the effort to collect structured semantic
 information about images.
 However, it is necessary to make inferences about this information (cancer
 lesions) using biological and physiological relationships between image
 metadata.
\end_layout

\begin_layout Standard
Image metadata in AIM format, does not allow represent information about
 image findings in a format that is directly suitable for reasoning.
 AIM provides only a format for data transfer and storage.
 We can see then that there is a lack of semantic methods to make inferences
 about cancerous lesions from semantic annotations of images, based on standard
 format such as AIM.
 Thus, in this work we developed reasoning approach based on staging systems
 such as the Classification of Malignant Tumors (TNM).
 In order to automatically staging cancer patients and finally incorporate
 these methods to the requirements met by an image annotation systems as
 ePAD.
\end_layout

\begin_layout Section

\lang american
Objective
\end_layout

\begin_layout Standard
The objective of this work is to automatically determine the cancer stage
 of lesions present in medical images, using semantic web and reasoning
 technologies to process semantic annotations made by experts to provide
 clinicians a second opinion on the classification of their patients.
 This semantic annotations are made using tools that use xml schema to describe
 and save image findings as the AIM format(ePad).
 Automatic cancer staging can increase the efficiency of radiologists and
 oncologists and improve the quality and uniformity of image interpretation
 by experts.
 It is important to mention that the current work focuses on staging liver
 cancer due to data availability.
\end_layout

\begin_layout Standard
The remainder of the paper is organized as follows.
 the Section 3 presents related works.
 Section 4 describes our methodology composed by the ontological representation
 of AIM 4.0 model, the conditions to implement the TNM classifier(General
 Ontology) and the formal representation of cancer staging.
 Section 5 presents the experimental test.
 Section 6 concludes the paper.
\end_layout

\begin_layout Section
Related work
\end_layout

\begin_layout Standard
Currently, there are other cancer staging systems, however, they are not
 open source and their classification methods cannot be analyzed or reused
 openly
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2014"

\end_inset

.
 Cancer staging is a classification process to determine how much cancer
 there is on the whole body and where it is located.
 Prior research on cancer staging have used semantic annotations, from a
 controlled vocabulary, for discovering implicit knowledge:
\end_layout

\begin_layout Standard
Works like 
\begin_inset CommandInset citation
LatexCommand citet
key "Dameron2006Table"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "marquet2007"

\end_inset

 perform reasonig based on classification systems such as TNM and WHO using
 ontology class reasoning approach, which is theoretically correct, but
 in practice it has limitations as the creation of unnecessary classes,
 increasing the complexity of the ontology.
 Following the above limitation appears other called Open World Assuntion
 (OWA) that was solve by these studies avoiding the reasoning based on instances.
 However, it is possible to perform reasoning based on instances supported
 by data structures that will be described in detail at following sections.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "Tutac2008"

\end_inset

,
\begin_inset CommandInset citation
LatexCommand cite
key "Tutac2010"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand citet
key "Massicano2015AnOF"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "zillner:towards"

\end_inset

, they create Ontologies in OWL-DL for TNM.
 However, the idea of having an ontology for each type of body organ is
 undesirable as in the case of 
\begin_inset CommandInset citation
LatexCommand cite
key "zillner:towards"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "Tutac2008"

\end_inset

.
 We believe in the approach of having an ontology representing directly
 image findings (such as the ontology model of AIM) and besides that, the
 classification tasks as cancer staging should be guided only by rules and
 axioms.
\end_layout

\begin_layout Standard
Although in 
\begin_inset CommandInset citation
LatexCommand cite
key "Meriem2012"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Racoceanu20152"

\end_inset

and 
\begin_inset CommandInset citation
LatexCommand citet
key "Tutac2010"

\end_inset

 the authors used semantic image annotations and performs a classification
 based on Nottingham grading System(NGS) supported by OWL and SWRL.
 The fact of create a new ontology depending on the condition you want to
 analyze it is a limiting factor.
 This however, does not occur in our approach, wich provides an ontology
 based on a standard such AIM.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "Moller2013"

\end_inset

,
\begin_inset CommandInset citation
LatexCommand cite
key "Zillner2012"

\end_inset

 can be found the closest approach to our proposal.
 However, ignoring the fact that the data used are not available for all
 the necessary analysis, the lymphoma staging system that has been implemented
 in this study is relatively simpler than TNM staging system.
 For example, we can see in 
\begin_inset CommandInset citation
LatexCommand cite
key "Zillner2012"

\end_inset

 does not consider the size of a lesion as an important factor.
 However, this fact is very important in staging systems more complex as
 TNM of liver, lung, etc.
 Moreover, we can see that the process of aligning all ontologies generated
 on this study are not described explicitly.
\end_layout

\begin_layout Standard
Recent works using ePAD 
\begin_inset CommandInset citation
LatexCommand cite
key "Gimenez2011,Kurtz20141082"

\end_inset

 propose an image retrieval framework based on semantic annotations.
 This framework incorporates the semantic correlations between terms used
 to describe these images.
 This automated approach provides real time support for radiologists, showing
 them images associated with similar diagnoses.
\end_layout

\begin_layout Standard
In the literature, we found similar systems where semantic annotations are
 stored in different formats that do not allow their integration for reasoning
 processes.
 Often these formats are also proprietary.
 Some of these studies also allow creating image annotations in AIM format
 (in XML), but these are not suitable for reasoning.
 AIM format provides only a transfer and storage format.
 
\end_layout

\begin_layout Standard
Our work is focused on helping cancer specialists in automatic patient classific
ation (staging) using semantic annotations in images.
 The classification shall be made ​​using semantic reasoning on annotations
 encoded in AIM, these annotations, made by radiologists, describe lesions
 in images.
\end_layout

\begin_layout Section
Method description
\end_layout

\begin_layout Standard
In this section we describe the methodology to be followed.
 Our approach comprises three tasks:
\end_layout

\begin_layout Itemize
The ontological representation of AIM 4.0 model.
 
\end_layout

\begin_layout Itemize
Generate conditions to implement the TNM classifier(General Ontology)
\end_layout

\begin_layout Itemize
Formal Representation of Cancer Staging
\end_layout

\begin_layout Subsection
The ontological representation of AIM model.
 
\end_layout

\begin_layout Standard
In order to perform inference and classification from image annotations
 based on the AIM model, we need a language equipped with a formal semantics.
 Using this semantics, inferences about ontologies and its individuals can
 be made.
 In this context the OWL Web Ontology Language describes a language for
 building an ontological representation semantically equivalent of an informatio
n model, such as Annotation and Image Markup AIM.
 In this work we transformed the AIM data model into an equivalent ontological
 representation, using OWL2.
 This transformation was performed by creating classes and properties in
 OWL that are user-understandable and suitable for inference.
\end_layout

\begin_layout Standard
We developed this OWL model based on the ontology provides by Hakan Bulu
 
\begin_inset CommandInset citation
LatexCommand cite
key "Bulu"

\end_inset

.
 However, This ontology represents the AIM 3.0 version model.
 Therefore, in order to represent the AIM 4.0 model, which is the version
 used to store image annotations generated by tools such as ePAD
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2011"

\end_inset

, we expanded the Hakan Bulu ontology based on AIM 4.0 UML class diagram,
 which is available online
\begin_inset Foot
status open

\begin_layout Plain Layout
https://wiki.nci.nih.gov/display/AIM/Extending+the+AIM+Model
\end_layout

\end_inset

 and named this new ontology such as AIM4-O.
 
\end_layout

\begin_layout Subsubsection
AIM4-O ontology
\end_layout

\begin_layout Description
Classes
\end_layout

\begin_layout Standard
In general, the AIM version 4.0 is an extension of the AIM Foundation model.
 It has nine additional classes, supporting lesion tracking derived during
 image-based clinical trials.
 In this work we considered the following six classes as suficient to achieve
 our goal:
\end_layout

\begin_layout Enumerate

\series bold
AIM:Entity:
\series default
 It is an abstract class that represents the existence of a thing, concept,
 observation, calculation, measurement and graphic design on AIM.
\end_layout

\begin_layout Enumerate

\series bold
AIM:AnnotationCollection: 
\series default
It is an abstract concept of container which contains elements such as 
\series bold
\emph on
:ImageAnnotation
\series default
\emph default
 or 
\series bold
\emph on
:AnnotationOfAnnotation entities.
\end_layout

\begin_layout Enumerate

\series bold
AIM:imageAnnotationCollection: 
\series default
Stores instances of 
\series bold
\emph on
:AnnotationImages
\series default
\emph default
 class and it is related with the 
\series bold
\emph on
:Person
\series default
\emph default
 class which contains patient demographic information.
\end_layout

\begin_layout Enumerate

\series bold
AIM:ImagingPhysicalEntity
\begin_inset Foot
status open

\begin_layout Plain Layout
The only class in the model that has been changed the entire name 
\series bold
to AnatomicEntity 
\series default
in AIM 3.0 version
\end_layout

\end_inset

:
\series default
 This class stores an anatomical location as a coded term ( RID2662, femur,
 RadLex ) based on controlled vocabularies such as RadLex®, SNOMED CT®,
 Unified Medical Language System (UMLS).
\end_layout

\begin_layout Enumerate

\series bold
AIM:ImagingPhysicalCharacteristic: 
\series default
This class describes the 
\series bold
\emph on
:ImagingPhysicalEntity
\series default
\emph default
 as coded term.

\series bold
 
\end_layout

\begin_layout Enumerate

\series bold
AIM:MarkupEntity: 
\series default
This class captures textual information and graphical representation as
 DICOM-SR and SCOORD3D, for tridimensional and bidimensional spatial coordinates.
\end_layout

\begin_layout Description
Relationships 
\end_layout

\begin_layout Standard
Relationships associate concepts via semantic relations, for example an
 
\series bold
\emph on
:ImageAnnotation
\series default
\emph default
 having an Observation that describes a lesion.
 The relationship representations in this ontology enable semantic reasoning,
 which is a prerequisite for semantic classification and searching.
 The relations are important because they describe how different concepts
 relate to each other.
 
\end_layout

\begin_layout Standard
One of the basic concept in AIM4-O ontology is the 
\series bold
\emph on
:ImageAnnotation
\series default
\emph default
 entity, this concept allows us to describe various data properties in OWL
 of an image annotation, such as its comments, name, date and time of creation.
 For example, the creation day of some image annotation is represented as
 
\series bold
\emph on
dateTime
\series default
\emph default
 data property and assigned a date value.
 Therefore, we can say that the statement
\series bold
\emph on
 :imageAnnotation1 dateTime {"2014-09-26T17:07:58ˆˆdatetime"}
\series default
\emph default
 states that an annotation that is referred as imageAnnotation1 it was created
 at 2014-09-26T17:07:58.
 Similary to the above, other relationship of Image Annotation to other
 concepts, such as physical location of lesions or observations, can be
 specified using relationship in OWL.
 Finally, The other classes were related to each other using the properties
 shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:AIM4example"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/AIM4.pdf
	lyxscale 30
	scale 13

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:AIM4example"

\end_inset


\lang brazilian
This diagram describes the abstract classes as purple oval involving your
 instance (imageAnnotationCollection, ImageAnnotation, geometricShape) and
 relationships as red arrows
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The following example illustrates and shows the OWL encoding (in Manchester
 syntax) of an AIM4-O individual that represents image findings.
 This example highlights the difference between Xml (as a serialization
 format) and OWL (as data model) in representation of image anntotation.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="1">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XML 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\ttfamily},tabsize=4"
inline false
status open

\begin_layout Plain Layout

<imageAnnotations> 
\end_layout

\begin_layout Plain Layout

<ImageAnnotation> 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

<UNIQUEIDENTIFIER root="f3fftpf6wsinx4o17il0t3a9o7fr1x7gyr9uye82"/> 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

<dateTime value="2014-10-05T22:33:47"/> 
\end_layout

\begin_layout Plain Layout

<name value="Liver1"/> <comment value="CT / RECON 2: LIVER 2 PHASE (AP)
 / 37"/> 
\end_layout

\begin_layout Plain Layout

.
 
\end_layout

\begin_layout Plain Layout

.
 
\end_layout

\begin_layout Plain Layout

.
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Manchester syntax
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\ttfamily},tabsize=4"
inline false
status open

\begin_layout Plain Layout

@prefix xsd:  <http://www.w3.org/2001/XMLSchema#> .
 
\end_layout

\begin_layout Plain Layout

@prefix aim:  <http://www.w3.org/ns/aim4#> .
\end_layout

\begin_layout Plain Layout

Individual: 8ixmtfhbiqujozezrep1r90t1n0po8wxyfy5svzs
\end_layout

\begin_layout Plain Layout

     Types:						 ImageAnnotationCollection          
\end_layout

\begin_layout Plain Layout

     Facts:
\end_layout

\begin_layout Plain Layout

	    aim:hasImageAnnotations     :9gs43xqj1kyl13lmega0zhoenzvgeakkprft8fw8,
\end_layout

\begin_layout Plain Layout

.
\end_layout

\begin_layout Plain Layout

Individual: f3fftpf6wsinx4o17il0t3a9o7fr1x7gyr9uye82
\end_layout

\begin_layout Plain Layout

     Types:						 ImageAnnotation
\end_layout

\begin_layout Plain Layout

     Facts:        
\end_layout

\begin_layout Plain Layout

        aim:hasImageReference      :sj1...,
\end_layout

\begin_layout Plain Layout

        aim:hasMarkupEntity        :jma...,
\end_layout

\begin_layout Plain Layout

        aim:hasCalculationEntity   :a4l...,
\end_layout

\begin_layout Plain Layout

        aim:hasImagingObservation  :hoj...,
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        AIM:HASPHYSICALENTITY      :1A5GZINZFTM1OXC45SHO8GOK2J8YRL7YEBO7WXX0,
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        aim:dateTime               "2014-10-05T22:33:47"^^xsd:dateTime,
\end_layout

\begin_layout Plain Layout

        aim:uniqueIdentifier       "f3fftpf6wsinx4o17il0t3a9o7fr1x7gyr9uye82"^^x
sd:string,            
\end_layout

\begin_layout Plain Layout

        aim:comment                "CT / RECON 2: LIVER 2 PHASE (AP) / 37"^^xsd:
string,      
\end_layout

\begin_layout Plain Layout

        aim:name                   "Liver1"^^xsd:string
\end_layout

\begin_layout Plain Layout

.
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:sample-of-Image"

\end_inset

sample of Image Annotations in XML and OWL format
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:sample-of-Image"

\end_inset

 shows syntax of a sample AIM ImageAnnotation with 
\series bold
\emph on
uniqueIdentifier
\series default
\emph default
 "f3fftpf6wsinx4o17il0t3a9o7fr1x7gyr9uye82" instance in AIM 4.0 XML format,
 the same shows the OWL manchester syntax of the same AIM 
\series bold
\emph on
:ImageAnnotation
\series default
\emph default
 instance in an AIM 4.0 OWL file.
 We can see, in table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:sample-of-Image"

\end_inset

, the concept of PhysicalEntity with 
\series bold
\emph on
uniqueIdentifier
\series default
\emph default
 "1a5gzinzftm1oxc45sho8gok2j8yrl7yebo7wxx0", related to the Image Annotation
 by 
\series bold
hasPhysicalEntity
\series default
 Object Property.
 The table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Sample-of-AIM"

\end_inset

 shows the syntax of a sample 
\series bold
\emph on
:PhysicalEntity
\series default
\emph default
 instance in AIM 4.0 XML.
 the same shows the OWL manchester syntax of the same 
\series bold
\emph on
:PhysicalEntity
\series default
\emph default
 instance in an AIM 4.0 OWL file.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="1">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
XML
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\ttfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

<imagingPhysicalEntityCollection> 
\end_layout

\begin_layout Plain Layout

 <ImagingPhysicalEntity> 
\end_layout

\begin_layout Plain Layout

   <uniqueIdentifier root="1a5gzinzftm1oxc45sho8gok2j8yrl7yebo7wxx0"/> 
\end_layout

\begin_layout Plain Layout

   <typeCode code="RID58" codeSystem="liver" 
\end_layout

\begin_layout Plain Layout

                          codeSystemName="RadLex" codeSystemVersion=""/>
 
\end_layout

\begin_layout Plain Layout

   <typeCode code="RID67" codeSystem="Couinaud hepatic segment 7" 
\end_layout

\begin_layout Plain Layout

                          codeSystemName="RadLex.3.10" codeSystemVersion=""/>
 
\end_layout

\begin_layout Plain Layout

   <annotatorConfidence value="0.0"/> 
\end_layout

\begin_layout Plain Layout

   <label value="Location"/> 
\end_layout

\begin_layout Plain Layout

 </ImagingPhysicalEntity> 
\end_layout

\begin_layout Plain Layout

</imagingPhysicalEntityCollection> 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Manchester syntax
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\ttfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

Individual:  1a5gzinzftm1oxc45sho8gok2j8yrl7yebo7wxx0
\end_layout

\begin_layout Plain Layout

    Types:						  ImagingPhysicalEntity          
\end_layout

\begin_layout Plain Layout

	Facts:        
\end_layout

\begin_layout Plain Layout

  	aim:annotatorConfidence     0.0f,      
\end_layout

\begin_layout Plain Layout

  	aim:label                   "Location"^^xsd:string,      
\end_layout

\begin_layout Plain Layout

  	aim:typeCode                
\end_layout

\begin_layout Plain Layout

            "{codeSystemName=RadLex,codeSystem=liver,code=RID58,codeSystemVersio
n=}"^^xsd:string, 
\end_layout

\begin_layout Plain Layout

  	aim:typeCode                
\end_layout

\begin_layout Plain Layout

            "{codeSystemName=RadLex.3.10,codeSystem=Couinaudhepaticsegment7,code=R
ID67}"^^xsd:string,      
\end_layout

\begin_layout Plain Layout

  	aim:uniqueIdentifier        "1a5gzinzftm1oxc45sho8gok2j8yrl7yebo7wxx0"^^xsd:s
tring
\end_layout

\begin_layout Plain Layout

.
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Sample-of-AIM"

\end_inset

Sample of AIM PhysicalEntity in XML and OWL format
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Generate conditions to implement the TNM classifier
\end_layout

\begin_layout Subsubsection
Transforming AIM-XML Annotations to OWL Instances 
\end_layout

\begin_layout Standard
The second step is to define a mechanism to transform existing AIM-XML documents
 to their equivalent encoded using OWL ( AIM4-O individuals).
 We developed a script to perform this task.
 This script uses the groovy language to automatically map XML documents
 to AIM classes, which are represented as a set of java classes based on
 the AIM 4.0 UML model.
 
\end_layout

\begin_layout Standard
Subsequently, the OWL-api (a Java API and reference implementation for creating,
 manipulating and serialising OWL Ontologies) was used to create OWL Instances
 from those AIM java classes, thus allowing the script to process streams
 of XML documents and populate an OWL knowledge base with their content.
 
\end_layout

\begin_layout Standard
With the above, we are in a position to develop ontology-based and rule-based
 reasoning mechanisms to work with AIM annotations.
 
\end_layout

\begin_layout Subsubsection
TNM classifier(General Ontology)
\end_layout

\begin_layout Standard
In order to staging automatically the cancer, our approach must have the
 support of capable ontology to specify the semantics of image observations
 of a particular domain, in this case, this ontology should be able to represent
 the topology of a human body organ, this organ in which the cancer starts
 growing and has its own TNM system, in this work this organ was the liver.
 Furthermore, it is considered necessary to include an OWL representation
 of Radlex vocabulary in order to facilite handling AIM4-O individuals,
 because these individuals have terminology Radlex in its structure.
 Finally, it was added to the ontology the set of rules based on the TNM
 liver system.
 The result was 
\series bold
the general ontology
\series default
 constructed from the above-mentioned requirements.
\end_layout

\begin_layout Subsubsection
General Ontology 
\end_layout

\begin_layout Standard
The ontology is divided in 4 files, as seen on Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:generalOntology"

\end_inset

:
\end_layout

\begin_layout Itemize
The AIM4-O ontology with individuals obtained using the above processes.
\end_layout

\begin_layout Itemize
The TNM staging system, axioms and rules.
\end_layout

\begin_layout Itemize
The Liver Ontology (based on the Onlira ontology 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokciyan2014"

\end_inset

).
\end_layout

\begin_layout Itemize
Radlex lexicon module taken from 
\begin_inset Foot
status open

\begin_layout Plain Layout
http://bioportal.bioontology.org/ontologies/RADLEX/classes
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/ontologiageral2.pdf
	lyxscale 30
	scale 10

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:generalOntology"

\end_inset

General Ontology components and imports diagram.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The following sections give a description of the ontologies used as part
 of the General Ontology.
\end_layout

\begin_layout Subsubsection
Classes for TNM concepts and staging system
\end_layout

\begin_layout Standard
In order to get an OWL representation of each TNM stage, we need an interpretati
on of its TNM definition.
 Although it is not mentioned explicitly, the TNM criteria are exclusive,
 so the corresponding OWL classes were made disjoint.
 For example, the T2 stage criterion is represented by the union of two
 restrictions representing respectively a single tumor (any size) that has
 grown into blood vessels (T2_a class), and a single tumor no larger than
 5 cm (T2_b class).
 
\end_layout

\begin_layout Subsubsection
ONLIRA (Ontology of the Liver for Radiology)
\end_layout

\begin_layout Standard
This ONLIRA ontology was developed as part of the CaReRa project.
 ONLIRA aims to model imaging observations of the liver domain with an emphasis
 on properties and relations between the liver, hepatic veins, and liver
 lesions.
 The design of ONLIRA was based on elicitation sessions with radiologists
 for gaining insight into liver imaging observations.
 ONLIRA can be found online 
\begin_inset Foot
status open

\begin_layout Plain Layout
https://bioportal.bioontology.org/ontologies/ONLIRA
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Parts of this ontology were used to represent the liver topography described
 in AIM-xml annotations generated by ePAD
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2014"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Radlex terminology 
\end_layout

\begin_layout Standard
AIM provides an XML schema that describes the anatomic structures and visual
 observations in images utilizing the RadLex terminology.
 We used parts of RadLex to represent these anatomical structures and to
 represent TNM classification criteria in OWL.
 The TNM criteria refer to entity locations and anatomical structures.
 Then it is important that our general ontology contains not only the anatomical
 structures mentioned in the staging criteria, but also the various parts
 direct and indirect connected to them.
 For example, to the N and M criteria we added 2 super classes 
\series bold
\emph on
:adjacentOrganGroup
\series default
\emph default
 that describes the set of organs adjacent to a main organ (i.e.
 liver) and 
\series bold
\emph on
:noadjacentOrganGroup
\series default
\emph default
 that describes organs based on the most common sites of tumor dissemination
\begin_inset CommandInset citation
LatexCommand cite
key "Faria2014"

\end_inset

.
 For the liver, we included lungs and bones as no adjacent organs, as seen
 in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:radlexclass"

\end_inset

.
\end_layout

\begin_layout Subsection
Formal Representation of TNM Cancer Staging 
\end_layout

\begin_layout Standard
In the previous sections, several operations were necessary to enhance the
 General ontology or TNM classifier.
 First, we added new classes and properties to fill the gap between the
 tumor features, described in the AIM-xml model, and classes present in
 the AIM4-O Ontology.
 Second, we provided definitions for all TNM stages, liver topography and
 RadLex terminology in order to represent their knowledge in OWL.
 
\end_layout

\begin_layout Standard
Finally, to achieve the goal of staging cancer from image annotations, we
 used subclass, intersection, equivalence, disjunction between classes,
 object properties and some rules as reasoning mechanisms using only expressiven
ess OWL + SWRL.
 This process will be described below.
\end_layout

\begin_layout Description
The cancer staging is divided in two main steps.
 The first step consists in giving a score starting from the description
 of the tumor (T), the spreading into lymphatic nodes (N) and possible metastasi
s (M); the second step consists in determining the stage according to the
 previous scores.
 In order to discover the limits of OWL’s abilities and the capabilities
 provided by adding rules and axioms, we attempted to formally define and
 implement the staging conditions, which TNM system demands, using only
 OWL expressivity if possible (only OWL + SWRL).
\end_layout

\begin_layout Standard
We decided that the following conditions reflected a desirable staging process:
 
\end_layout

\begin_layout Itemize
Condition 1 : Cancer staging should consider the existence of solitary or
 multiple tumor in the same site
\end_layout

\begin_layout Itemize
Condition 2 : Staging should consider if tumors are either bigger or minor
 than certain size X in cm 
\end_layout

\begin_layout Itemize
Condition 3 : Staging should consider lesions in adjacent organs 
\end_layout

\begin_layout Subsubsection
Asserting Conditions using OWL 
\end_layout

\begin_layout Description

\series bold
Condition 1 : 
\series default
Cancer staging should consider the existence of solitary or multiple tumor
 in the same site
\end_layout

\begin_layout Standard
The AIM4-O ontology (previously developed) does not have mechanics such
 as classes, subclasses or properties that allow us to infer whether a patient
 has single or multiple tumors explicitly.
 In the case of multiple tumors, we constructed the following rule 
\series bold
\emph on
:MoreThanOneTumo
\series default
\emph default
r (in SWRL notation):
\end_layout

\begin_layout Standard

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline ImageStudy(?X)\land isImageStudyOf(?x,?y)\land isImageStudyOf(?x,?z)\land\\
DifferentFrom(?y,?z)\rightarrow MoreThanOneTumor(?x)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Standard
This rule classifies an 
\series bold
\emph on
:ImageStudy
\series default
\emph default
 as member of 
\series bold
\emph on
:MorethanOneTumor
\series default
\emph default
 class, if an image study "X" is referenced by more than one image annotation.
 In order to classify something as 
\series bold
\emph on
:MorethanOneTumor
\series default
\emph default
, we created one new concept maned
\series bold
\emph on
 isImageStudyOf
\series default
\emph default
.
 This concept is the inverse of the 
\series bold
\emph on
hasImageStudy
\series default
\emph default
 object property.
 The 
\series bold
\emph on
hasImageStudy
\series default
\emph default
 property relates an 
\series bold
\emph on
:ImageAnnotation
\series default
\emph default
 entity to an 
\series bold
\emph on
:ImageStudy
\series default
\emph default
 entity.
 
\end_layout

\begin_layout Standard
In order to classify patients with exactly one tumor identified.
 We did not find axioms or rules that satisfy this requirement because OWL
 has an open world assumption.
 Open world means that, just because we do not say something it does not
 mean that it is not true.
 For example, I can say that the patient annotation describes a cancer lesion
 using the 
\series bold
\emph on
:ImagingObservation
\series default
\emph default
 entity of the AIM4-O ontology model, but unless I explicitly say that there
 are no other lesions, it is assumed that there may be other lesion that
 I just have not mentioned or described.
\end_layout

\begin_layout Standard
To solve the open world assumption problem, we considered some alternatives.
 We could have modeled again our ontology by setting the “hasImagingObservation”
 object property as a class of AIM ontology.
 But, this did not seem intuitive to us.
 Instead, we decided to state the number of lesions explicitly by creating
 one new concept named 
\series bold
\emph on
singleLesion
\series default
\emph default
, as an object property of 
\series bold
\emph on
:ImageStudy
\series default
\emph default
 entity.
 This concept indicates if the image study describes only one cancer lesion.
 We assumed that image studies describe exactly one cancer lesion (“singleLesion
 {true}”), if it is referenced by only one image annotation.
 It was not possible to formulate with only OWL.
 Instead, this information was provided by the data structure shown in the
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:AIMDataStructure"

\end_inset

, this structure was generated as part of the process of parsing the XML
 image annotations to create AIM4-O individuals.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/TNM Staging Documentation.pdf
	scale 45

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:AIMDataStructure"

\end_inset

 Data Structure generated as part of parsing XML files to individuals AIM4-O
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Finally, to classify annotations that describe a single lesion, we constructed
 the rule 
\series bold
\emph on
:SingleTumor
\series default
\emph default
 (in SWRL notation): 
\end_layout

\begin_layout Standard

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline ImageStudy(?X)\land singleLesion(?X,?val)\land\\
equal(?val,true)\rightarrow singleTumor(?X)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Description
Condition 2: Staging should consider if tumors are either bigger or minor
 than certain size X in cm.
\end_layout

\begin_layout Standard
This condition is easily implemented by getting the value from the data
 property "
\series bold
\emph on
values
\series default
\emph default
" on the 
\series bold
\emph on
:CalculationResult
\series default
\emph default
 entity.
 This entity is related to the 
\series bold
\emph on
:ImageAnnotation
\series default
\emph default
 entity through the 
\series bold
\emph on
hasCalculationEntity
\series default
\emph default
 object property.
 In order to satisfy this measurement condition, we formulate the following
 rules taking 5cm as measure just as TNM for liver (in SWRL notation): 
\end_layout

\begin_layout Standard
\noindent
\align center

\series bold
\lang brazilian
LessThan5cmTumor:
\series default
 
\end_layout

\begin_layout Standard
\noindent
\align center

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline ImageAnnotation(?x)\land hasCalculationEntity(?x,?y)\land hasCalculationResult(?y,?z)\land\\
values(?z,?val)\land lessThan(?val,5)\rightarrow lessThan5cmTumor(?x)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center

\series bold
\lang brazilian
MoreThan5cmTumor:
\series default
 
\end_layout

\begin_layout Standard
\noindent
\align center

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline ImageAnnotation(?x)\land hasCalculationEntity(?x,?y)\land hasCalculationResult(?y,?z)\land\\
values(?z,?val)\land greaterThan(?val,5)\rightarrow MoreThan5cmTumor(?x)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Description
Condition 3: Staging should consider lesions in adjacent organs 
\end_layout

\begin_layout Standard
We have to consider the fact that a lesion has to spread out to satisfy
 more complicated criterion of classification.
 For that, we needed to create one new concept based on the 
\series bold
\emph on
:Lesion
\series default
\emph default
 class from the Onlira ontology[ref to onlira].
 While 
\series bold
\emph on
:Lesion
\series default
\emph default
 class handles important characteristics of a lesion, such as composition,
 density, size, shape, etc, unfortunately this is not enough for TNM classificat
ion and reasoning.
 For this reason, we added 3 properties to it and createed the subclass
 
\series bold
:OutsideLesion
\series default
, these properties are :
\end_layout

\begin_layout Itemize

\series bold
\emph on
hasLocation
\series default
\emph default
 (object property): This property indicates the location of lesions based
 on Radlex taxonomy.
 this property relates Onlira Lesion Classes members to Radlex AnatomicalEntity
 Class members.
 
\end_layout

\begin_layout Itemize

\series bold
\emph on
isRegionalLymphNodeAffected
\series default
\emph default
 (data property): This property specifies whether the lesion is located
 in some lymph node.
 It was useful to enable classification criteria such as N0 and N1.
 
\end_layout

\begin_layout Itemize

\series bold
\emph on
isAdjacentOrgan
\series default
\emph default
 (data property): It indicates whether the lesion with 
\series bold
\emph on
hasLocation
\series default
\emph default
 "X" is close to organ "Y".
 According to the TNM liver classification criterion (case of study in this
 work), we considered as adjacent organs to the liver
\begin_inset CommandInset citation
LatexCommand cite
key "Faria2014"

\end_inset

: the pancreas, duodenum, liver, colon etc.
 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:radlexclass"

\end_inset

).
 We group these concepts as organs in radlex representation creating two
 new classes ":
\series bold
\emph on
AdjacentOrganGroup
\series default
\emph default
" and ":
\series bold
\emph on
NoAdjacentOrganGroup
\series default
\emph default
":
\end_layout

\begin_layout Standard
\noindent
\align center

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline NoAdjacentOrganGroup\subseteq RadlexEntity.Organ\\
AdjacentOrganGroup\subseteq RadlexEntity.Organ\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Standard

\series bold
\emph on
\lang brazilian
:AdjacentOrganGroup
\series default
\emph default
 and 
\series bold
\emph on
:NoAdjacentOrganGroup
\series default
\emph default
 classes indicate whether an organ is considered adjacent or not in reference
 to the parent organ.
 The parent organ represents the type of staging, for our case study the
 parent organ was the liver.
 Finally, we constructed the following rule (in SWRL notation) to indicates
 whether an 
\series bold
\emph on
:OutsideLesion
\series default
\emph default
 is located in an adjacent organ:
\end_layout

\begin_layout Standard
\noindent
\align center

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline Lesion(?x)\land adjacentOrganGroup(?y)\land\\
hasLocation(?x,?y)\rightarrow isAdjacentOrgan(?x,true)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Standard

\lang brazilian
At this point, once we covered the above requirements adequately using OWL
 and SWRL, we constructed the axioms and rules in order to be able to automatica
lly classify cancer lesions based on the TNM system.
 We noticed that the way we modeled things mattered.
 For example, it was easier to define N1a, N0 and to reuse their definitions
 for M0, rather than to start with the definition of M0 handling complex
 closures.
 With the use of the AIM4-O ontology, concepts can easily be related to
 each other as demonstrated previously.
 Furthermore, integrity and cardinality requirements can be specified and
 enforced for reasoning purposes.
 
\end_layout

\begin_layout Standard

\lang brazilian
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/drawingRadlextaxonomyLiver.pdf
	lyxscale 50
	scale 17

\end_inset


\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:radlexclass"

\end_inset

Getting the subclass-hierarchy from established ontologies.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Experimental Study and Results
\end_layout

\begin_layout Standard
In this section we evaluated firstly the expressivity of AIM4-O ontology,
 followed by, how our classifier is used to automatically classify image
 findings based on TNM criteria, which is the objective of this work.
 Finally the quantitative evaluation of TNM classifier was made using precision
 and recall.
 
\end_layout

\begin_layout Subsection
Data sets
\end_layout

\begin_layout Standard
Our first dataset is a set of real clinical reports of hepatocellular carcinoma
 (HCC) patients from The NCI's Genomic Data Commons (GDC).
 In this work all experiments were supported by the GDC data.
 On the other hand and more important for image metadata classification
 was the requirement to have a dataset of images to validate the results
 of GDC clinical reports, The TCIA 
\begin_inset CommandInset citation
LatexCommand cite
key "Blomqvist2012"

\end_inset

 is a service which de-identifies and hosts a large archive of medical images
 of cancer accessible for public download and also it is related with GDC
 by 
\emph on
a patient Subject ID
\emph default
.
 The imaging modality selected was computed tomography (CT), then, those
 images were loaded into the annotation tool ePAD.
 
\end_layout

\begin_layout Standard
While the evaluation of cancer staging could be applied to other cancer,
 this work focuses on staging liver cancer (HCC) for reasons of clinical
 data and image availability.
 For a given patient, the input to the system consists of AIM files(image
 annotations ) and the output, consist of the Cancer Staging for this patient.
\end_layout

\begin_layout Subsection
Quantitative assesment of AIM4-O ontology
\end_layout

\begin_layout Standard
According to 
\begin_inset CommandInset citation
LatexCommand cite
key "Blomqvist2012"

\end_inset

 
\emph on
Ontological evaluation is the process of assessing an ontology with respect
 to certain criteria, using certain measures
\emph default
.
 In this work, we undertook the evaluation of the AIM4-O ontology from the
 functional point of view [2].
 In order to evaluate the functionality of the ontology, we describe ontology
 assessment as a task-focused evaluation of ontologies against their ontological
 requirements such as competency questions (CQs) and inference requirements
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokciyan2014"

\end_inset

.
 
\end_layout

\begin_layout Standard
In order to evaluate the AIM4-O ontology, we studied and evaluated how it
 could help in searching clinical reports that describe image findings (reports
 about cancer ), for this purpose, were compared two different approaches
 (CQs): 
\end_layout

\begin_layout Itemize
Based on ontologies (semantic search): If reports on image findings are
 described as AIM4-O ontology individuals, the reports can be searched using
 description logic query languages, such as DL query 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokciyan2014"

\end_inset

:
\end_layout

\begin_layout Itemize
Based keyword search: Clinical reports and image findings are usually written
 in natural language, therefore, an method for searching can be keyword
 search.
\end_layout

\begin_layout Standard
In order to highlight the differences between these two approaches, we describe
 four queries expressed both in DL (DL query) and keywords (see Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:queries"

\end_inset

):
\end_layout

\begin_layout Enumerate
Q1 - Find all reports related to an image observation (tumor observation)
 
\end_layout

\begin_layout Enumerate
Q2 - Find all reports that describe multiple tumors 
\end_layout

\begin_layout Enumerate
Q3 - Find all reports that contain a tumor observation that has a size greater
 than 8 cm 
\end_layout

\begin_layout Enumerate
Q4 - Find all reports that contain a tumor observation with descriptors
 (i.e invasion, mass, vascular) 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="1.5cm">
<column alignment="center" valignment="top" width="7cm">
<column alignment="center" valignment="top" width="2.5cm">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Query ID
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DL query
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Keyword query
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasAnnotations some (hasImageAnnotations some (hasImagingObservation some
 (ImagingObservationEntity and label value "Lesion type "))) 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tumor 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasAnnotations min 2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Multiple tumor 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasAnnotations some (hasImageAnnotations some (hasCalculationEntity some
 (hasCalculationResult some (some values float [> 8.0f])))) 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tumor size greater than 8 cm 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hasImagingObservationCharacteristic 1 min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Vascular tumor invasion mass 
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:queries"

\end_inset

Description logic and keyword representation for four queries
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
We have considered the following points in order to evaluate both approaches:
 
\end_layout

\begin_layout Itemize
The evaluation is based on a data set of GDC reports: We took 15 random
 radiology reports of different patients written in natural language and
 converted them into AIM4-O instances.
 
\end_layout

\begin_layout Itemize
A report was retrieved if it satisfied the DL query or if it contained all
 of the keywords in the search query.
 
\end_layout

\begin_layout Itemize
Finally, we compared precision and recall against the gold standard.
 The gold standard was determined by a radiologist manually.
 
\end_layout

\begin_layout Standard
The four queries with corresponding precision and recall results are shown
 in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:prexrecallontology"

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="10">
<features tabularvalignment="middle">
<column alignment="left" valignment="top" width="1.2cm">
<column alignment="left" valignment="top" width="0pt">
<column alignment="left" valignment="top" width="0.8cm">
<column alignment="left" valignment="top" width="0.9cm">
<column alignment="left" valignment="top" width="0.7cm">
<column alignment="left" valignment="top" width="0.9cm">
<column alignment="left" valignment="top" width="0.8cm">
<column alignment="left" valignment="top" width="0.9cm">
<column alignment="left" valignment="top" width="0.7cm">
<column alignment="left" valignment="top" width="0.8cm">
<row>
<cell multicolumn="1" alignment="left" valignment="top" rightline="true" usebox="none" width="1.8cm">
\begin_inset Text

\begin_layout Plain Layout
Query ID
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q1
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" rightline="true" usebox="none" width="1.5cm">
\begin_inset Text

\begin_layout Plain Layout
Q2
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q3
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Q4
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DL-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Key-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DL-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Key-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DL-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Key-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DL-Query
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Key-Query
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Semantic Search
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
P
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.67
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
R
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Keyword Search
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
P
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
R
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.8
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.7
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:prexrecallontology"

\end_inset

R=recall and P=precision values for four queries 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Description
Observations 
\end_layout

\begin_layout Standard
By analyzing the four queries we can see that the semantic search has the
 greatest number of relevant documents retrieved: 
\end_layout

\begin_layout Standard
Q1: With the semantic approach, 15 reports were retrieved with a precision
 and recall of 1 (15/15).
 With the keyword search, 12 reports were retrieved with a precision of
 1 (12/12) and recall of 0.8 (12/15).
 Q2: With the semantic approach, 5 reports were retrieved with a precision
 and recall of 1 (5/5).
 With the keyword search, 5 reports were retrieved with a precision and
 recall of 0.4 (2/5).
 Q3: With the semantic search, 10 reports were retrieved with a precision
 of 0.9 (9/10) and recall of 0.9 (9/10).
 With the keyword search no reports were retrieved, because there were not
 any reports that contained all the query words (i.e., lesion size greater
 than 8 cm).
 Q4: With the semantic search, 15 reports were retrieved with a precision
 of 0.67 (10/15) and recall of 1 (10/10).
 With the keyword search, 7 reports were retrieved with a precision of 1
 (7/7) and recall of 0.7 (7/10).
\end_layout

\begin_layout Standard
The semantic search performed better, with recall values close to 1 and
 always better than the keyword search.
 Also, in all but one case, precision values were better for the semantic
 search.
 The keyword search had 0 precision and recall for the query 3, which is
 a very bad result.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Classification of image findings with AIM4-O using Recist Criteria
\end_layout

\begin_layout Plain Layout
The RECIST (Response Evaluation Criteria In Solid Tumors) guideline allows
 a standardized assessment of tumor burden and tumor response during therapy.
 Here, a sum of the diameters for all target lesions is calculated and reported
 as the baseline for follow-up and indicates therapy response/failure
\begin_inset CommandInset citation
LatexCommand cite
key "Recist"

\end_inset

.
 
\end_layout

\begin_layout Plain Layout
A considerable part of guidelines on Recist criteria can be automated using
 the AIM4-O ontology model and image annotations.
 However, this is not done by defining logical axioms and SWRL rules in
 OWL, as we do with other types classification such as TNM.
 That happens because Recist is based on value comparisons and OWL uses
 an open world assumption.
 Instead, we use SPARQL to retrieve relevant data to classify findings by
 comparing their measurement values to size specifications provided by Recist.
 
\end_layout

\end_inset


\end_layout

\begin_layout Description
\begin_inset Note Note
status collapsed

\begin_layout Description
Recist specifications:
\end_layout

\begin_layout Plain Layout
Baseline documentation of “Target” and “Non-Target” lesions
\end_layout

\begin_layout Itemize
All measurable lesions, up to a maximum of 2 lesions per organ and 5 lesions
 in total, representative of all involved organs should be identified as
 target lesions, recorded and measured at baseline.
 
\end_layout

\begin_layout Itemize
A sum of the Longest Diameter (LD), for all target lesions, will be calculated
 and reported as the baseline sum LD.
 The baseline sum LD will be used as reference by which to characterize
 the objective tumor response.
 
\end_layout

\begin_layout Itemize
All other lesions (or sites of disease) should be identified as non-target
 lesions and should also be recorded at baseline.
 Measurements of these lesions are not required, but the presence or absence
 of each should be noted throughout follow-up.
\end_layout

\begin_layout Description
Response Criteria evaluation of target lesions
\end_layout

\begin_layout Itemize
Complete Response (CR): Disappearance of all target lesions 
\end_layout

\begin_layout Itemize
Partial Response (PR): At least a 30% decrease in the LD sum of the target
 lesions, taking as reference the baseline LD sum.
 
\end_layout

\begin_layout Itemize
Stable Disease (SD): Neither sufficient shrinkage to qualify for PR nor
 sufficient increase to qualify for PD, taking as reference the smallest
 LD sum since the treatment started.
 
\end_layout

\begin_layout Itemize
Progressive Disease (PD): At least a 20% increase in the LD sum of the target
 lesions, taking as reference the smallest LD sum recorded since the treatment
 started or the appearance of one or more new lesions 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsubsection
Asserting Recist guidelines using OWL and SPARQL
\end_layout

\begin_layout Plain Layout
The guidelines of Recist in detail in 
\begin_inset CommandInset citation
LatexCommand cite
key "Recist"

\end_inset

, represent rules and most of them were implemented using SPARQL (rules
 related to non-target lesions were not implemented):
\end_layout

\begin_layout Plain Layout

\series bold
Selection of target lesions
\series default
:The selection of final target lesions, from the set of potential lesions,
 is performed by the radiologist.
 However, this selection can also be implement using the following rule
 (in SWRL notation):
\end_layout

\begin_layout Plain Layout
\begin_inset space \space{}
\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\series bold
Srwl rule that classifies potential target lesions based on tumor size (<15mm):
\end_layout

\begin_layout Plain Layout
\noindent
\align center

\lang brazilian
\begin_inset Formula 
\begin{gather*}
\hline ImageAnnotation(?x)\land hasCalculationEntity(?x,?y)\\
\land hasCalculationResult(?y,?z)\\
values(?z,?val)\land greaterThan(?val,1.5)\rightarrow isAdjacentOrgan(?x,true)\\
\hline 
\end{gather*}

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang brazilian
Verification of target lesions:
\series default
 It is verified that there are at most five target lesions selected and
 that each organ appears at most twice as the lesion location.
 This is done by the following SPARQL ASK queries: 
\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="1">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sparql query that verifies that there are at most five target lesions
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang brazilian
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\rmfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

PREFIX owl: <http://www.w3.org/2002/07/owl#>     	
\end_layout

\begin_layout Plain Layout

PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>     	
\end_layout

\begin_layout Plain Layout

PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>     
\end_layout

\begin_layout Plain Layout

PREFIX onto: <http://www.owl-ontologies.com/Ontology1311106921.owl#>     	
\end_layout

\begin_layout Plain Layout

ASK where { Select (count(?lesion) as ?log) where {     		
\end_layout

\begin_layout Plain Layout

		?anotation onto:hasPerson onto:Xindividual.
     		
\end_layout

\begin_layout Plain Layout

		?anotation onto:hasImageAnnotations ?imageanotation.
     		
\end_layout

\begin_layout Plain Layout

		?imageanotation onto:hasImagingObservation ?observation.
     		
\end_layout

\begin_layout Plain Layout

		?observation onto:typeCode ?typeCode.
     		
\end_layout

\begin_layout Plain Layout

		FILTER regex(str(?typeCode),'Lesion Baseline Evaluation')     		
\end_layout

\begin_layout Plain Layout

		?imageanotation onto:hasLesion ?lesion.
     		
\end_layout

\begin_layout Plain Layout

		} 
\end_layout

\begin_layout Plain Layout

	having (?log <= 5 ) 
\end_layout

\begin_layout Plain Layout

}; 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sparql query that verifies that there are at most five target lesions
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang brazilian
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\rmfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> 
\end_layout

\begin_layout Plain Layout

PREFIX owl: <http://www.w3.org/2002/07/owl#> 
\end_layout

\begin_layout Plain Layout

PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>       	
\end_layout

\begin_layout Plain Layout

PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>       
\end_layout

\begin_layout Plain Layout

PREFIX onto:<http://www.owl-ontologies.com/Ontology1311106921.owl#> 
\end_layout

\begin_layout Plain Layout

ASK where {  
\end_layout

\begin_layout Plain Layout

	SELECT (count(?location) as ?log) where {         		
\end_layout

\begin_layout Plain Layout

      ?anotation onto:hasPerson onto:Xindividual.
         		
\end_layout

\begin_layout Plain Layout

      ?anotation onto:hasImageAnnotations ?imageanotation.
          		
\end_layout

\begin_layout Plain Layout

      ?imageanotation onto:hasImagingObservation ?observation.
          	
\end_layout

\begin_layout Plain Layout

	  ?observation onto:typeCode ?typeCode.
          	
\end_layout

\begin_layout Plain Layout

	  FILTER regex(str(?typeCode),'Lesion Baseline Evaluation').
         	
\end_layout

\begin_layout Plain Layout

	  ?imageanotation onto:hasLesion ?lesion.
         	
\end_layout

\begin_layout Plain Layout

	  ?lesion onto:hasLocation ?location.
         		
\end_layout

\begin_layout Plain Layout

      ?location rdf:type onto:Xorgan.
         
\end_layout

\begin_layout Plain Layout

	} 
\end_layout

\begin_layout Plain Layout

having (?log <= 2) 
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang brazilian
Calculation of RECIST sum:
\series default
 This operation is easily implemented by getting the values from the value
 property on the CalculationResult entity.
 This entity is related to the ImageAnnotation entity through the hasCalculation
Entity object property (AIM4-O ontology), as shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:AIM4example"

\end_inset

.
 The shortest axis (lymph nodes) and longest axis (other lesions) are summed
 for all target lesions by the follow SPARQL queries: 
\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="1">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sparql query that sums shorest and longest axis of all target lesion.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash

\backslash

\end_layout

\end_inset

The “
\series bold
Xdatatime
\series default
” variable can be “Lesion Baseline Evaluation” or “Follow Up”
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang brazilian
\begin_inset listings
lstparams "language=XML,basicstyle={\tiny\rmfamily},tabsize=5"
inline false
status open

\begin_layout Plain Layout

PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>     
\end_layout

\begin_layout Plain Layout

PREFIX owl: <http://www.w3.org/2002/07/owl#>     	
\end_layout

\begin_layout Plain Layout

PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>     	
\end_layout

\begin_layout Plain Layout

PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>     	
\end_layout

\begin_layout Plain Layout

PREFIX onto:<http://www.owl-ontologies.com/Ontology1311106921.owl#>     	
\end_layout

\begin_layout Plain Layout

SELECT ( SUM(?values) as ?sum) where {     	
\end_layout

\begin_layout Plain Layout

	?anotation onto:hasPerson onto:Xindividual.
     	
\end_layout

\begin_layout Plain Layout

	?anotation onto:hasImageAnnotations ?imageanotation.
      
\end_layout

\begin_layout Plain Layout

	?imageanotation onto:hasImagingObservation ?observation.
      
\end_layout

\begin_layout Plain Layout

	?observation onto:typeCode ?typeCode.
      	
\end_layout

\begin_layout Plain Layout

	FILTER regex(str(?typeCode),'Xdatatime').
     
\end_layout

\begin_layout Plain Layout

	?imageanotation onto:hasCalculationEntity ?calculation.
     	
\end_layout

\begin_layout Plain Layout

	?calculation onto:hasCalculationResult ?calcresult.
     	
\end_layout

\begin_layout Plain Layout

	?calcresult onto:values ?values.
     
\end_layout

\begin_layout Plain Layout

} 
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang brazilian
Classification of response:
\series default
 Finally, the classification of complete response(CP), partial response
 (PR) or stable disease (SD) is carried out in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ShowsRecist"

\end_inset

: 
\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/recistResult.jpg
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout

\lang brazilian
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:ShowsRecist"

\end_inset

Shows the response classification PD (Progressive Disease: at least a 20%
 increase in the LD sum of target lesions) of a patient with one lesion
 in the liver “liver2” , with studies on dates october 31 and september
 26.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang brazilian
The reasoning, based on the four guidelines above, provide an automated
 estimate of the tumor burden, according to the RECIST criteria, on imaging
 studies at baseline and follow-up.
 This information will enable oncologists to calculate and classify patients
 response.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
TNM Staging
\end_layout

\begin_layout Standard
To evaluate the ability of our TNM classifier, we firstly created a template
 named "TNM template" to provide the radiologist with a pre-specified set
 of semantic terms for image annotation.
 All image annotations were stored in the AIM standard format and are compatible
 by ePAD 
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2014"

\end_inset

.
 An example of an annotated image is presented in Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:TNMtemplate"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/templateTNM.pdf
	lyxscale 50
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:TNMtemplate"

\end_inset

A CT image of the liver annotated with TNM template on the right of the
 image 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Subsequently, we generated image annotations, in AIM-XML, and classified
 automatically them using the TNM criteria, this process was duly evaluated
 and correctly acepted by an experienced radiologist, he visually analyzed
 the validity of the generated annotations in terms of semantic.
 The process we followed was:
\end_layout

\begin_layout Itemize
The data set used came from the following open databases:
\end_layout

\begin_deeper
\begin_layout Itemize
The NCI's Genomic Data Commons (GDC)
\begin_inset Foot
status open

\begin_layout Plain Layout
https://gdc.cancer.gov/
\end_layout

\end_inset

 .
\end_layout

\begin_layout Itemize
The Cancer Imaging Archive (TCIA)
\begin_inset Foot
status open

\begin_layout Plain Layout
https://public.cancerimagingarchive.net/ncia/login.jsf
\end_layout

\end_inset

 (that contains only images, number of series and studies): As we working
 with TNM classification from liver, we searched for "LIHC - Liver hepatocellula
r carcinoma" obtaining 52 patients with information available in both databases
 (images and reports).
 However, information about tumor size was obtained by manual review of
 the medical reports.
 These reports are also available in the The NCI's Genomic Data Commons.
\end_layout

\end_deeper
\begin_layout Itemize
After reading the medical reports, the radiologist was provided with an
 excel spreadsheet that provided information about medical findings as lesion
 size, vascular invasion and others.
\end_layout

\begin_layout Itemize
Using this excel file and data from the Genomic Data GDC we created the
 AIM XML annotations and integrated it into our knowledge base(as individuals
 of AIM4-O).
\end_layout

\begin_layout Itemize
The AIM files were used as input TNM classifier.
 We compared the results with the TNM values that physicians reported.
 
\end_layout

\begin_layout Standard
We automatically classificated all image annotations based on 52 different
 clinical reports, in order to analyze the potencial of the automatic TNM
 staging approach we discussed the patient staging scenarios with the help
 of our expert and project partner at the Stanford University, the response
 was positive.
 The precision was 84.3 % and the recall 74.4%, the evaluation results are
 summarized in the color scale matrix in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:matrixconfusion"

\end_inset

.
 This represents a confusion matrix for a multi cancer stage classification,
 For initial cancer stage such as I,II,IIIA, the number of incorrect classificat
ions (i.e.
 false positives and false negatives) was very small.
 It is represented by the highlighted diagonal of the matrix in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:matrixconfusion"

\end_inset

.
 This is because, the cancer stages such IIIB or IVA are described by concepts
 more complex relatively, for example we can see in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:histogram"

\end_inset

 that, the number of true positives in Stage IIIB is less than StageIVA.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/confusionmatrix2.pdf
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:matrixconfusion"

\end_inset

Confusion matrix for TNM multi-stage classification
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
In addition, the classifier revealed the fact that there are some clinical
 reports cases with staging diagnosis inaccurate, presents in The NCI's
 Genomic Data Common
\begin_inset Foot
status open

\begin_layout Plain Layout
https://gdc.cancer.gov/
\end_layout

\end_inset

, for example, in the context of particular patients such as the patient
 with Subject 
\emph on
ID TCGA-DD-A1EJ,
\emph default
 the staging result of our TNM classifier was correct after validation by
 our expert.
 The stage predicted was 
\emph on
Stage I
\emph default
 in contrast with the information present in 
\begin_inset Foot
status open

\begin_layout Plain Layout
https://gdc-portal.nci.nih.gov/cases/52292ffc-0902-4d97-b461-20723987a177
\end_layout

\end_inset

.
 Such patient examples show the importace of improve clinical decision support
 systems by processing of image metadata in cancer assessment.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/classhistogram.pdf
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:histogram"

\end_inset

Summary of Histograms for each class-stage, before automatic TNM classification
 of image metadata of 52 reports
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard

\lang american
The process of cancer staging in patients by image analysis is a task performed
 by specialists, such as oncologists and radiologists, that often entails
 intensive work that requires precision in the interpretation of cancer
 lesions.
 Expert accuracy is achieved through training and experience
\begin_inset CommandInset citation
LatexCommand citep
key "Depeursinge2014"

\end_inset

, but variations in image interpretation is a limitation of human observes.
 In this context, we developed an automatic staging approach (TNM classifier)
 that is a strong medical need.
 It can help experts obtain a higher accuracy rate in interpretation.
 
\end_layout

\begin_layout Standard
For achieved this, firstly, in this work the AIM4-O ontology was developed
 and validated using concrete clinical cases, this ontology represented
 the opening for more complex task such cancer staging by image annotations
 using the AIM format.
 Subsequently, were developed the necessary conditions to make possible
 the cancer staging, this conditions they based on formal representacion
 (rules, axioms and automatic reasoning procedure) of how different AIM
 concepts should interact with other knowledge bases such as Radlex and
 Onlira.
\end_layout

\begin_layout Standard
The result was the TNM classifier and using real cancer cases our experiments
 demonstrated the importace of improve clinical decision support systems
 by processing of image finding and metadata in cancer assessment with 84.3
 % presicion and 74.4% recall.
 In addition, the analysis of real patient reports contrasting the automated
 staging result, revealed the fact that there are patient cases with a diagnosis
 inacurate.
 But, it is important to note that the automatic staging procedure does
 not give the clinician new information, as it was said above, it can be
 seen as a second opinion for the purposes of quality in clinical diagnosis.
\end_layout

\begin_layout Standard
We also highlighted some of the limitations of description logics-based
 classification for this task of tumor staging such OWA.
 This was addressed by using a simple data structure.
 Although we have not actually done it, we assume that our approach could
 be applied to other kinds of cancer such liver, lungs ,etc by modifying
 the rules and axioms that represent the TNM criteria thus avoiding to create
 an entire new ontology.
\end_layout

\begin_layout Standard
Some limitations to this work is that our dataset is small.
 Because, both medical images CT and clinical reports have to be present
 for one patient for optimal validation.
\end_layout

\begin_layout Standard

\lang american
Other systems, such as mint Lesion (MintMedical GmbH, Dossenheim, Germany)
 and syngo.via (Siemens Healthcare, Malvern) are proprietary software, i.e,
 all data on images that are stored internally are in a proprietary format
 that can not be accessed by third parties 
\begin_inset CommandInset citation
LatexCommand cite
key "Rubin2011"

\end_inset

.
\end_layout

\begin_layout Standard

\lang american
Finally, we believe our approach can be generalized to other cases of reasoning
 based on image findings, using the AIM model establishes an automated workflow
 where image annotations produced by an imaging system, whatever that generates
 AIM files, will transform the image metadata into OWL instances, then these
 instances will be used for reasoning procedures in different fields.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references/refsjournal"
options "elsarticle-num-names"

\end_inset


\end_layout

\end_body
\end_document
